/*
Copyright 2022 The Katalyst Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/ // Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: cpu.proto

package cpuadvisor

import (
	"context"
	"fmt"
	"io"
	"math"
	math_bits "math/bits"
	"reflect"
	"strings"

	_ "github.com/gogo/protobuf/gogoproto"
	"github.com/gogo/protobuf/proto"
	github_com_gogo_protobuf_sortkeys "github.com/gogo/protobuf/sortkeys"
	"google.golang.org/grpc"
	"google.golang.org/grpc/codes"
	"google.golang.org/grpc/status"
	_ "k8s.io/kubelet/pkg/apis/resourceplugin/v1alpha1"

	"github.com/kubewharf/katalyst-core/pkg/agent/qrm-plugins/advisorsvc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion3 // please upgrade the proto package

type OverlapType int32

const (
	OverlapType_OverlapWithPod  OverlapType = 0
	OverlapType_OverlapWithPool OverlapType = 1
)

var OverlapType_name = map[int32]string{
	0: "OverlapWithPod",
	1: "OverlapWithPool",
}

var OverlapType_value = map[string]int32{
	"OverlapWithPod":  0,
	"OverlapWithPool": 1,
}

func (x OverlapType) String() string {
	return proto.EnumName(OverlapType_name, int32(x))
}

func (OverlapType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{0}
}

type ListAndWatchResponse struct {
	Entries              map[string]*CalculationEntries `protobuf:"bytes,1,rep,name=entries,proto3" json:"entries,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	XXX_NoUnkeyedLiteral struct{}                       `json:"-"`
	XXX_sizecache        int32                          `json:"-"`
}

func (m *ListAndWatchResponse) Reset()      { *m = ListAndWatchResponse{} }
func (*ListAndWatchResponse) ProtoMessage() {}
func (*ListAndWatchResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{0}
}
func (m *ListAndWatchResponse) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *ListAndWatchResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_ListAndWatchResponse.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *ListAndWatchResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ListAndWatchResponse.Merge(m, src)
}
func (m *ListAndWatchResponse) XXX_Size() int {
	return m.Size()
}
func (m *ListAndWatchResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_ListAndWatchResponse.DiscardUnknown(m)
}

var xxx_messageInfo_ListAndWatchResponse proto.InternalMessageInfo

func (m *ListAndWatchResponse) GetEntries() map[string]*CalculationEntries {
	if m != nil {
		return m.Entries
	}
	return nil
}

type CalculationEntries struct {
	Entries              map[string]*CalculationInfo `protobuf:"bytes,1,rep,name=entries,proto3" json:"entries,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	XXX_NoUnkeyedLiteral struct{}                    `json:"-"`
	XXX_sizecache        int32                       `json:"-"`
}

func (m *CalculationEntries) Reset()      { *m = CalculationEntries{} }
func (*CalculationEntries) ProtoMessage() {}
func (*CalculationEntries) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{1}
}
func (m *CalculationEntries) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *CalculationEntries) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_CalculationEntries.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *CalculationEntries) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CalculationEntries.Merge(m, src)
}
func (m *CalculationEntries) XXX_Size() int {
	return m.Size()
}
func (m *CalculationEntries) XXX_DiscardUnknown() {
	xxx_messageInfo_CalculationEntries.DiscardUnknown(m)
}

var xxx_messageInfo_CalculationEntries proto.InternalMessageInfo

func (m *CalculationEntries) GetEntries() map[string]*CalculationInfo {
	if m != nil {
		return m.Entries
	}
	return nil
}

type CalculationInfo struct {
	// valid values:
	// 1. "dedicated" (dedicated_cores container with or without numa_biding)
	// 2. real pool name (shared_cores container entries and pool entries)ï¼Œ, including:
	//    - common pools (eg. share, reclaim, flink, batch, bmq)
	//    - pools generated by qos aware server containing isolated shared_cores containers (eg. isolation0, isolation1, ...)
	OwnerPoolName             string                           `protobuf:"bytes,1,opt,name=owner_pool_name,json=ownerPoolName,proto3" json:"owner_pool_name,omitempty"`
	CalculationResultsByNumas map[int64]*NumaCalculationResult `protobuf:"bytes,2,rep,name=calculation_results_by_numas,json=calculationResultsByNumas,proto3" json:"calculation_results_by_numas,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	XXX_NoUnkeyedLiteral      struct{}                         `json:"-"`
	XXX_sizecache             int32                            `json:"-"`
}

func (m *CalculationInfo) Reset()      { *m = CalculationInfo{} }
func (*CalculationInfo) ProtoMessage() {}
func (*CalculationInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{2}
}
func (m *CalculationInfo) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *CalculationInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_CalculationInfo.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *CalculationInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CalculationInfo.Merge(m, src)
}
func (m *CalculationInfo) XXX_Size() int {
	return m.Size()
}
func (m *CalculationInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_CalculationInfo.DiscardUnknown(m)
}

var xxx_messageInfo_CalculationInfo proto.InternalMessageInfo

func (m *CalculationInfo) GetOwnerPoolName() string {
	if m != nil {
		return m.OwnerPoolName
	}
	return ""
}

func (m *CalculationInfo) GetCalculationResultsByNumas() map[int64]*NumaCalculationResult {
	if m != nil {
		return m.CalculationResultsByNumas
	}
	return nil
}

type NumaCalculationResult struct {
	// every block doesn't overlap with other blocks in same NumaCalculationResult
	Blocks               []*Block `protobuf:"bytes,2,rep,name=blocks,proto3" json:"blocks,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *NumaCalculationResult) Reset()      { *m = NumaCalculationResult{} }
func (*NumaCalculationResult) ProtoMessage() {}
func (*NumaCalculationResult) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{3}
}
func (m *NumaCalculationResult) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *NumaCalculationResult) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_NumaCalculationResult.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *NumaCalculationResult) XXX_Merge(src proto.Message) {
	xxx_messageInfo_NumaCalculationResult.Merge(m, src)
}
func (m *NumaCalculationResult) XXX_Size() int {
	return m.Size()
}
func (m *NumaCalculationResult) XXX_DiscardUnknown() {
	xxx_messageInfo_NumaCalculationResult.DiscardUnknown(m)
}

var xxx_messageInfo_NumaCalculationResult proto.InternalMessageInfo

func (m *NumaCalculationResult) GetBlocks() []*Block {
	if m != nil {
		return m.Blocks
	}
	return nil
}

type Block struct {
	Result               uint64           `protobuf:"varint,1,opt,name=result,proto3" json:"result,omitempty"`
	OverlapTargets       []*OverlapTarget `protobuf:"bytes,2,rep,name=overlap_targets,json=overlapTargets,proto3" json:"overlap_targets,omitempty"`
	BlockId              string           `protobuf:"bytes,3,opt,name=block_id,json=blockId,proto3" json:"block_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *Block) Reset()      { *m = Block{} }
func (*Block) ProtoMessage() {}
func (*Block) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{4}
}
func (m *Block) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *Block) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_Block.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *Block) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Block.Merge(m, src)
}
func (m *Block) XXX_Size() int {
	return m.Size()
}
func (m *Block) XXX_DiscardUnknown() {
	xxx_messageInfo_Block.DiscardUnknown(m)
}

var xxx_messageInfo_Block proto.InternalMessageInfo

func (m *Block) GetResult() uint64 {
	if m != nil {
		return m.Result
	}
	return 0
}

func (m *Block) GetOverlapTargets() []*OverlapTarget {
	if m != nil {
		return m.OverlapTargets
	}
	return nil
}

func (m *Block) GetBlockId() string {
	if m != nil {
		return m.BlockId
	}
	return ""
}

type OverlapTarget struct {
	OverlapTargetPoolName      string      `protobuf:"bytes,1,opt,name=overlap_target_pool_name,json=overlapTargetPoolName,proto3" json:"overlap_target_pool_name,omitempty"`
	OverlapTargetPodUid        string      `protobuf:"bytes,2,opt,name=overlap_target_pod_uid,json=overlapTargetPodUid,proto3" json:"overlap_target_pod_uid,omitempty"`
	OverlapTargetContainerName string      `protobuf:"bytes,3,opt,name=overlap_target_container_name,json=overlapTargetContainerName,proto3" json:"overlap_target_container_name,omitempty"`
	OverlapType                OverlapType `protobuf:"varint,4,opt,name=overlap_type,json=overlapType,proto3,enum=cpuadvisor.OverlapType" json:"overlap_type,omitempty"`
	XXX_NoUnkeyedLiteral       struct{}    `json:"-"`
	XXX_sizecache              int32       `json:"-"`
}

func (m *OverlapTarget) Reset()      { *m = OverlapTarget{} }
func (*OverlapTarget) ProtoMessage() {}
func (*OverlapTarget) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{5}
}
func (m *OverlapTarget) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *OverlapTarget) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_OverlapTarget.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *OverlapTarget) XXX_Merge(src proto.Message) {
	xxx_messageInfo_OverlapTarget.Merge(m, src)
}
func (m *OverlapTarget) XXX_Size() int {
	return m.Size()
}
func (m *OverlapTarget) XXX_DiscardUnknown() {
	xxx_messageInfo_OverlapTarget.DiscardUnknown(m)
}

var xxx_messageInfo_OverlapTarget proto.InternalMessageInfo

func (m *OverlapTarget) GetOverlapTargetPoolName() string {
	if m != nil {
		return m.OverlapTargetPoolName
	}
	return ""
}

func (m *OverlapTarget) GetOverlapTargetPodUid() string {
	if m != nil {
		return m.OverlapTargetPodUid
	}
	return ""
}

func (m *OverlapTarget) GetOverlapTargetContainerName() string {
	if m != nil {
		return m.OverlapTargetContainerName
	}
	return ""
}

func (m *OverlapTarget) GetOverlapType() OverlapType {
	if m != nil {
		return m.OverlapType
	}
	return OverlapType_OverlapWithPod
}

type GetCheckpointRequest struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *GetCheckpointRequest) Reset()      { *m = GetCheckpointRequest{} }
func (*GetCheckpointRequest) ProtoMessage() {}
func (*GetCheckpointRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{6}
}
func (m *GetCheckpointRequest) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *GetCheckpointRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_GetCheckpointRequest.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *GetCheckpointRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_GetCheckpointRequest.Merge(m, src)
}
func (m *GetCheckpointRequest) XXX_Size() int {
	return m.Size()
}
func (m *GetCheckpointRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_GetCheckpointRequest.DiscardUnknown(m)
}

var xxx_messageInfo_GetCheckpointRequest proto.InternalMessageInfo

type GetCheckpointResponse struct {
	Entries              map[string]*AllocationEntries `protobuf:"bytes,1,rep,name=entries,proto3" json:"entries,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *GetCheckpointResponse) Reset()      { *m = GetCheckpointResponse{} }
func (*GetCheckpointResponse) ProtoMessage() {}
func (*GetCheckpointResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{7}
}
func (m *GetCheckpointResponse) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *GetCheckpointResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_GetCheckpointResponse.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *GetCheckpointResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_GetCheckpointResponse.Merge(m, src)
}
func (m *GetCheckpointResponse) XXX_Size() int {
	return m.Size()
}
func (m *GetCheckpointResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_GetCheckpointResponse.DiscardUnknown(m)
}

var xxx_messageInfo_GetCheckpointResponse proto.InternalMessageInfo

func (m *GetCheckpointResponse) GetEntries() map[string]*AllocationEntries {
	if m != nil {
		return m.Entries
	}
	return nil
}

type AllocationEntries struct {
	Entries              map[string]*AllocationInfo `protobuf:"bytes,1,rep,name=entries,proto3" json:"entries,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	XXX_NoUnkeyedLiteral struct{}                   `json:"-"`
	XXX_sizecache        int32                      `json:"-"`
}

func (m *AllocationEntries) Reset()      { *m = AllocationEntries{} }
func (*AllocationEntries) ProtoMessage() {}
func (*AllocationEntries) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{8}
}
func (m *AllocationEntries) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AllocationEntries) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_AllocationEntries.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *AllocationEntries) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AllocationEntries.Merge(m, src)
}
func (m *AllocationEntries) XXX_Size() int {
	return m.Size()
}
func (m *AllocationEntries) XXX_DiscardUnknown() {
	xxx_messageInfo_AllocationEntries.DiscardUnknown(m)
}

var xxx_messageInfo_AllocationEntries proto.InternalMessageInfo

func (m *AllocationEntries) GetEntries() map[string]*AllocationInfo {
	if m != nil {
		return m.Entries
	}
	return nil
}

type AllocationInfo struct {
	RampUp bool `protobuf:"varint,1,opt,name=ramp_up,json=rampUp,proto3" json:"ramp_up,omitempty"`
	// owner_pool_name indicates the real pool this entry belongs to, it may equal to
	// 1. real pool name shows up explicitly in GetCheckpointResponse, including:
	//    - common pools (eg. share, reclaim, flink, batch, bmq)
	//    - pools generated by qos aware server containing isolated shared_cores containers (eg. isolation0, isolation1, ...)
	// 2. "dedicated" (dedicated_cores container with or without numa_biding)
	// 3. "fallback" (dedicated_cores without numa_binding will be put to this fake pool when it can't allocate isolated cpuset for them), there is no AllocationInfo for this fake pool
	// 4. empty (the entry is ramping up)
	OwnerPoolName                    string            `protobuf:"bytes,2,opt,name=owner_pool_name,json=ownerPoolName,proto3" json:"owner_pool_name,omitempty"`
	TopologyAwareAssignments         map[uint64]string `protobuf:"bytes,3,rep,name=topology_aware_assignments,json=topologyAwareAssignments,proto3" json:"topology_aware_assignments,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	OriginalTopologyAwareAssignments map[uint64]string `protobuf:"bytes,4,rep,name=original_topology_aware_assignments,json=originalTopologyAwareAssignments,proto3" json:"original_topology_aware_assignments,omitempty" protobuf_key:"varint,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	XXX_NoUnkeyedLiteral             struct{}          `json:"-"`
	XXX_sizecache                    int32             `json:"-"`
}

func (m *AllocationInfo) Reset()      { *m = AllocationInfo{} }
func (*AllocationInfo) ProtoMessage() {}
func (*AllocationInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_08fc9a87e8768c24, []int{9}
}
func (m *AllocationInfo) XXX_Unmarshal(b []byte) error {
	return m.Unmarshal(b)
}
func (m *AllocationInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	if deterministic {
		return xxx_messageInfo_AllocationInfo.Marshal(b, m, deterministic)
	} else {
		b = b[:cap(b)]
		n, err := m.MarshalToSizedBuffer(b)
		if err != nil {
			return nil, err
		}
		return b[:n], nil
	}
}
func (m *AllocationInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AllocationInfo.Merge(m, src)
}
func (m *AllocationInfo) XXX_Size() int {
	return m.Size()
}
func (m *AllocationInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_AllocationInfo.DiscardUnknown(m)
}

var xxx_messageInfo_AllocationInfo proto.InternalMessageInfo

func (m *AllocationInfo) GetRampUp() bool {
	if m != nil {
		return m.RampUp
	}
	return false
}

func (m *AllocationInfo) GetOwnerPoolName() string {
	if m != nil {
		return m.OwnerPoolName
	}
	return ""
}

func (m *AllocationInfo) GetTopologyAwareAssignments() map[uint64]string {
	if m != nil {
		return m.TopologyAwareAssignments
	}
	return nil
}

func (m *AllocationInfo) GetOriginalTopologyAwareAssignments() map[uint64]string {
	if m != nil {
		return m.OriginalTopologyAwareAssignments
	}
	return nil
}

func init() {
	proto.RegisterEnum("cpuadvisor.OverlapType", OverlapType_name, OverlapType_value)
	proto.RegisterType((*ListAndWatchResponse)(nil), "cpuadvisor.ListAndWatchResponse")
	proto.RegisterMapType((map[string]*CalculationEntries)(nil), "cpuadvisor.ListAndWatchResponse.EntriesEntry")
	proto.RegisterType((*CalculationEntries)(nil), "cpuadvisor.CalculationEntries")
	proto.RegisterMapType((map[string]*CalculationInfo)(nil), "cpuadvisor.CalculationEntries.EntriesEntry")
	proto.RegisterType((*CalculationInfo)(nil), "cpuadvisor.CalculationInfo")
	proto.RegisterMapType((map[int64]*NumaCalculationResult)(nil), "cpuadvisor.CalculationInfo.CalculationResultsByNumasEntry")
	proto.RegisterType((*NumaCalculationResult)(nil), "cpuadvisor.NumaCalculationResult")
	proto.RegisterType((*Block)(nil), "cpuadvisor.Block")
	proto.RegisterType((*OverlapTarget)(nil), "cpuadvisor.OverlapTarget")
	proto.RegisterType((*GetCheckpointRequest)(nil), "cpuadvisor.GetCheckpointRequest")
	proto.RegisterType((*GetCheckpointResponse)(nil), "cpuadvisor.GetCheckpointResponse")
	proto.RegisterMapType((map[string]*AllocationEntries)(nil), "cpuadvisor.GetCheckpointResponse.EntriesEntry")
	proto.RegisterType((*AllocationEntries)(nil), "cpuadvisor.AllocationEntries")
	proto.RegisterMapType((map[string]*AllocationInfo)(nil), "cpuadvisor.AllocationEntries.EntriesEntry")
	proto.RegisterType((*AllocationInfo)(nil), "cpuadvisor.AllocationInfo")
	proto.RegisterMapType((map[uint64]string)(nil), "cpuadvisor.AllocationInfo.OriginalTopologyAwareAssignmentsEntry")
	proto.RegisterMapType((map[uint64]string)(nil), "cpuadvisor.AllocationInfo.TopologyAwareAssignmentsEntry")
}

func init() { proto.RegisterFile("cpu.proto", fileDescriptor_08fc9a87e8768c24) }

var fileDescriptor_08fc9a87e8768c24 = []byte{
	// 1015 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x9c, 0x56, 0x5d, 0x6f, 0x1b, 0x45,
	0x17, 0xf6, 0xc4, 0x69, 0x52, 0x9f, 0x7c, 0x4f, 0x93, 0xd4, 0xd9, 0xb7, 0xb1, 0x5c, 0xbf, 0x02,
	0x85, 0xa2, 0xd8, 0x4d, 0x82, 0x68, 0x95, 0x2b, 0x9c, 0x10, 0x85, 0xf2, 0xd1, 0x9a, 0xa5, 0x69,
	0x44, 0x6f, 0x56, 0xe3, 0xdd, 0x89, 0xbd, 0xca, 0xee, 0xce, 0x74, 0x67, 0xd6, 0xd1, 0x0a, 0x09,
	0xf1, 0x0f, 0xe0, 0x5f, 0x70, 0x8d, 0xc4, 0x1d, 0xfc, 0x80, 0x5e, 0x72, 0xc9, 0x25, 0x0d, 0x7f,
	0x81, 0x4b, 0x90, 0x90, 0x67, 0xd7, 0xf6, 0xac, 0xe3, 0x0f, 0xe0, 0xca, 0x73, 0xe6, 0x9c, 0xe7,
	0x39, 0xcf, 0x9e, 0xe3, 0x39, 0x3a, 0x50, 0xb0, 0x79, 0x54, 0xe5, 0x21, 0x93, 0x0c, 0x83, 0xcd,
	0x23, 0xe2, 0x74, 0x5c, 0xc1, 0x42, 0x63, 0xb7, 0xe5, 0xca, 0x76, 0xd4, 0xac, 0xda, 0xcc, 0xaf,
	0xb5, 0x58, 0x8b, 0xd5, 0x54, 0x48, 0x33, 0xba, 0x50, 0x96, 0x32, 0xd4, 0x29, 0x81, 0x1a, 0xa7,
	0x5a, 0xf8, 0x65, 0xd4, 0xa4, 0x57, 0x6d, 0x12, 0x5e, 0xa8, 0x93, 0x47, 0x65, 0x8d, 0x5f, 0xb6,
	0x6a, 0x84, 0xbb, 0xa2, 0x16, 0x52, 0xc1, 0xa2, 0xd0, 0xa6, 0xdc, 0x8b, 0x5a, 0x6e, 0x50, 0xeb,
	0xec, 0x11, 0x8f, 0xb7, 0xc9, 0x5e, 0xd7, 0x99, 0x12, 0x9d, 0x8d, 0x26, 0x22, 0x92, 0x78, 0xb1,
	0x90, 0xbb, 0x36, 0x0b, 0x69, 0x42, 0xd7, 0xa2, 0x81, 0xac, 0xbd, 0x0a, 0xfd, 0xdd, 0x84, 0x4b,
	0xd4, 0x52, 0xe5, 0xa2, 0x63, 0xf7, 0x8e, 0x96, 0xe8, 0xd8, 0x09, 0x6d, 0xe5, 0x27, 0x04, 0xeb,
	0x9f, 0xba, 0x42, 0xd6, 0x03, 0xe7, 0x9c, 0x48, 0xbb, 0x6d, 0x52, 0xc1, 0x59, 0x20, 0x28, 0x3e,
	0x85, 0x79, 0x1a, 0xc8, 0xd0, 0xa5, 0xa2, 0x88, 0xca, 0xf9, 0x9d, 0x85, 0xfd, 0xdd, 0xea, 0xa0,
	0x0a, 0xd5, 0x51, 0x90, 0xea, 0x49, 0x12, 0xdf, 0xfd, 0x89, 0xcd, 0x1e, 0xda, 0x78, 0x09, 0x8b,
	0xba, 0x03, 0xaf, 0x42, 0xfe, 0x92, 0xc6, 0x45, 0x54, 0x46, 0x3b, 0x05, 0xb3, 0x7b, 0xc4, 0xef,
	0xc1, 0xad, 0x0e, 0xf1, 0x22, 0x5a, 0x9c, 0x29, 0xa3, 0x9d, 0x85, 0xfd, 0x92, 0x9e, 0xe8, 0x98,
	0x78, 0x76, 0xe4, 0x11, 0xe9, 0xb2, 0x20, 0x65, 0x31, 0x93, 0xe0, 0xc3, 0x99, 0xc7, 0xa8, 0xf2,
	0x23, 0x02, 0x7c, 0x33, 0x02, 0x9f, 0x0c, 0x6b, 0x7f, 0x77, 0x32, 0xe5, 0x18, 0xe5, 0xe7, 0x53,
	0x95, 0xef, 0x65, 0x95, 0xff, 0x6f, 0x4c, 0x9a, 0x27, 0xc1, 0x05, 0xd3, 0x65, 0x7f, 0x3f, 0x03,
	0x2b, 0x43, 0x6e, 0xfc, 0x36, 0xac, 0xb0, 0xab, 0x80, 0x86, 0x16, 0x67, 0xcc, 0xb3, 0x02, 0xe2,
	0xd3, 0x34, 0xd1, 0x92, 0xba, 0x6e, 0x30, 0xe6, 0x3d, 0x25, 0x3e, 0xc5, 0x5f, 0xc1, 0x3d, 0x7b,
	0x00, 0xb5, 0x42, 0x2a, 0x22, 0x4f, 0x0a, 0xab, 0x19, 0x5b, 0x41, 0xe4, 0x13, 0x51, 0x9c, 0x51,
	0x1f, 0x7c, 0x38, 0x41, 0x89, 0x6e, 0x9b, 0x09, 0xfc, 0x28, 0x7e, 0xda, 0x05, 0x27, 0xdf, 0xbf,
	0x65, 0x8f, 0xf3, 0x1b, 0x0c, 0x4a, 0x93, 0xc1, 0x7a, 0x8d, 0xf2, 0x49, 0x8d, 0x1e, 0x65, 0x6b,
	0x74, 0x5f, 0x57, 0xd6, 0x05, 0xde, 0x20, 0xd4, 0x2b, 0x75, 0x04, 0x1b, 0x23, 0x63, 0xf0, 0x3b,
	0x30, 0xd7, 0xf4, 0x98, 0x7d, 0xd9, 0xfb, 0xe0, 0x35, 0x9d, 0xf6, 0xa8, 0xeb, 0x31, 0xd3, 0x80,
	0xca, 0xd7, 0x70, 0x4b, 0x5d, 0xe0, 0x4d, 0x98, 0x4b, 0xca, 0xa5, 0xe4, 0xcd, 0x9a, 0xa9, 0x85,
	0x8f, 0x60, 0x85, 0x75, 0x68, 0xe8, 0x11, 0x6e, 0x49, 0x12, 0xb6, 0xa8, 0xec, 0x91, 0x6e, 0xe9,
	0xa4, 0xcf, 0x92, 0x90, 0xe7, 0x2a, 0xc2, 0x5c, 0x66, 0xba, 0x29, 0xf0, 0x16, 0xdc, 0x56, 0xe9,
	0x2c, 0xd7, 0x29, 0xe6, 0x55, 0xdf, 0xe6, 0x95, 0xfd, 0xc4, 0xa9, 0xfc, 0x89, 0x60, 0x29, 0x03,
	0xc6, 0x8f, 0xa0, 0x98, 0x4d, 0x78, 0xa3, 0xe9, 0x1b, 0x19, 0xfa, 0x7e, 0xf3, 0x0f, 0x60, 0xf3,
	0x06, 0xd0, 0xb1, 0x22, 0xd7, 0x51, 0xc5, 0x2d, 0x98, 0x77, 0x86, 0x60, 0xce, 0x99, 0xeb, 0xe0,
	0x3a, 0x6c, 0x0f, 0x81, 0x6c, 0x16, 0x48, 0xe2, 0x76, 0xff, 0x6c, 0x2a, 0x65, 0xa2, 0xd7, 0xc8,
	0x60, 0x8f, 0x7b, 0x21, 0x2a, 0xef, 0x21, 0x2c, 0xf6, 0x29, 0x62, 0x4e, 0x8b, 0xb3, 0x65, 0xb4,
	0xb3, 0xbc, 0x7f, 0x77, 0x54, 0x79, 0x62, 0x4e, 0xcd, 0x05, 0x36, 0x30, 0x2a, 0x9b, 0xb0, 0x7e,
	0x4a, 0xe5, 0x71, 0x9b, 0xda, 0x97, 0x9c, 0xb9, 0x81, 0x34, 0xe9, 0xab, 0x88, 0x0a, 0x59, 0xf9,
	0x19, 0xc1, 0xc6, 0x90, 0x23, 0x1d, 0x3d, 0x1f, 0x0d, 0x3f, 0xdf, 0xaa, 0x9e, 0x68, 0x24, 0x66,
	0xcc, 0x0b, 0xfe, 0x72, 0xea, 0x0b, 0x3e, 0xc8, 0xfe, 0x3b, 0xb7, 0xf5, 0x4c, 0x75, 0xcf, 0x63,
	0xf6, 0xb8, 0xd1, 0xf3, 0x03, 0x82, 0xb5, 0x1b, 0x01, 0xf8, 0xc3, 0x61, 0xe9, 0x0f, 0x26, 0x12,
	0x8e, 0x91, 0xfd, 0x62, 0xaa, 0xec, 0x87, 0x59, 0xd9, 0xc6, 0xe8, 0x2c, 0xc3, 0x73, 0xe7, 0xaf,
	0x3c, 0x2c, 0x67, 0xbd, 0xf8, 0x2e, 0xcc, 0x87, 0xc4, 0xe7, 0x56, 0xc4, 0x15, 0xfd, 0x6d, 0x73,
	0xae, 0x6b, 0x9e, 0xf1, 0x51, 0xf3, 0x68, 0x66, 0xd4, 0x3c, 0xea, 0x80, 0x21, 0x19, 0x67, 0x1e,
	0x6b, 0xc5, 0x16, 0xb9, 0x22, 0x21, 0xb5, 0x88, 0x10, 0x6e, 0x2b, 0xf0, 0x69, 0x20, 0x45, 0x31,
	0xaf, 0x8a, 0xf0, 0x78, 0xbc, 0xbc, 0xea, 0xf3, 0x14, 0x5c, 0xef, 0x62, 0xeb, 0x03, 0x68, 0x52,
	0x92, 0xa2, 0x1c, 0xe3, 0xc6, 0xdf, 0x22, 0xf8, 0x3f, 0x0b, 0xdd, 0x96, 0x1b, 0x10, 0xcf, 0x9a,
	0xa0, 0x60, 0x56, 0x29, 0xf8, 0x60, 0x82, 0x82, 0x67, 0x29, 0xcb, 0x64, 0x25, 0x65, 0x36, 0x25,
	0xcc, 0xf8, 0x04, 0xb6, 0x27, 0x52, 0xe8, 0x6d, 0x9c, 0x4d, 0xda, 0xb8, 0xae, 0xb7, 0xb1, 0xa0,
	0xb5, 0xca, 0xf8, 0x02, 0xde, 0xfa, 0x47, 0xba, 0xfe, 0x0d, 0xe9, 0x83, 0xf7, 0x61, 0x41, 0x7b,
	0xa6, 0x18, 0xc3, 0x72, 0x6a, 0x9e, 0xbb, 0xb2, 0xdd, 0x60, 0xce, 0x6a, 0x0e, 0xdf, 0x81, 0x95,
	0xcc, 0x1d, 0xf3, 0x56, 0xd1, 0xfe, 0x1f, 0x08, 0xe0, 0xb8, 0x71, 0x56, 0x4f, 0xea, 0x87, 0x3f,
	0x87, 0xc5, 0xba, 0xe3, 0xf4, 0x27, 0x04, 0xde, 0xae, 0x0e, 0x56, 0x8c, 0x6a, 0xff, 0xfa, 0x33,
	0x2a, 0x89, 0x43, 0x24, 0x31, 0xca, 0xba, 0x5b, 0x07, 0xf6, 0x1e, 0x6f, 0x25, 0x87, 0x3f, 0x86,
	0x82, 0x49, 0x7d, 0xd6, 0xa1, 0x0d, 0xe6, 0xe0, 0x7b, 0x3a, 0xa0, 0x7f, 0x9d, 0xce, 0x0d, 0x63,
	0x7b, 0x8c, 0xb7, 0xcf, 0x75, 0x0a, 0x8b, 0xfa, 0x7a, 0x82, 0xd7, 0x74, 0xc0, 0x89, 0xcf, 0x65,
	0x6c, 0x94, 0xa7, 0xed, 0x32, 0x95, 0xdc, 0x43, 0xb4, 0x6f, 0x43, 0xe1, 0xb8, 0x71, 0xd6, 0x50,
	0x6b, 0x14, 0x7e, 0x01, 0x4b, 0x99, 0xc9, 0x83, 0xcb, 0x13, 0x86, 0x52, 0xa2, 0xf4, 0xfe, 0xd4,
	0xb1, 0x55, 0xc9, 0x1d, 0x89, 0xd7, 0x6f, 0x4a, 0xe8, 0xd7, 0x37, 0xa5, 0xdc, 0x37, 0xd7, 0x25,
	0xf4, 0xfa, 0xba, 0x84, 0x7e, 0xb9, 0x2e, 0xa1, 0xdf, 0xae, 0x4b, 0xe8, 0xbb, 0xdf, 0x4b, 0xb9,
	0x97, 0xff, 0x7d, 0xeb, 0xb3, 0x79, 0x54, 0x73, 0xe2, 0x80, 0xf8, 0xae, 0xcd, 0x99, 0xe7, 0xda,
	0x71, 0x6d, 0x20, 0xa6, 0x39, 0xa7, 0x96, 0xbf, 0x83, 0xbf, 0x03, 0x00, 0x00, 0xff, 0xff, 0x51,
	0xe0, 0x05, 0xbf, 0xe4, 0x0a, 0x00, 0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// CPUAdvisorClient is the client API for CPUAdvisor service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type CPUAdvisorClient interface {
	AddContainer(ctx context.Context, in *advisorsvc.ContainerMetadata, opts ...grpc.CallOption) (*advisorsvc.AddContainerResponse, error)
	RemovePod(ctx context.Context, in *advisorsvc.RemovePodRequest, opts ...grpc.CallOption) (*advisorsvc.RemovePodResponse, error)
	ListAndWatch(ctx context.Context, in *advisorsvc.Empty, opts ...grpc.CallOption) (CPUAdvisor_ListAndWatchClient, error)
}

type cPUAdvisorClient struct {
	cc *grpc.ClientConn
}

func NewCPUAdvisorClient(cc *grpc.ClientConn) CPUAdvisorClient {
	return &cPUAdvisorClient{cc}
}

func (c *cPUAdvisorClient) AddContainer(ctx context.Context, in *advisorsvc.ContainerMetadata, opts ...grpc.CallOption) (*advisorsvc.AddContainerResponse, error) {
	out := new(advisorsvc.AddContainerResponse)
	err := c.cc.Invoke(ctx, "/cpuadvisor.CPUAdvisor/AddContainer", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *cPUAdvisorClient) RemovePod(ctx context.Context, in *advisorsvc.RemovePodRequest, opts ...grpc.CallOption) (*advisorsvc.RemovePodResponse, error) {
	out := new(advisorsvc.RemovePodResponse)
	err := c.cc.Invoke(ctx, "/cpuadvisor.CPUAdvisor/RemovePod", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *cPUAdvisorClient) ListAndWatch(ctx context.Context, in *advisorsvc.Empty, opts ...grpc.CallOption) (CPUAdvisor_ListAndWatchClient, error) {
	stream, err := c.cc.NewStream(ctx, &_CPUAdvisor_serviceDesc.Streams[0], "/cpuadvisor.CPUAdvisor/ListAndWatch", opts...)
	if err != nil {
		return nil, err
	}
	x := &cPUAdvisorListAndWatchClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type CPUAdvisor_ListAndWatchClient interface {
	Recv() (*ListAndWatchResponse, error)
	grpc.ClientStream
}

type cPUAdvisorListAndWatchClient struct {
	grpc.ClientStream
}

func (x *cPUAdvisorListAndWatchClient) Recv() (*ListAndWatchResponse, error) {
	m := new(ListAndWatchResponse)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// CPUAdvisorServer is the server API for CPUAdvisor service.
type CPUAdvisorServer interface {
	AddContainer(context.Context, *advisorsvc.ContainerMetadata) (*advisorsvc.AddContainerResponse, error)
	RemovePod(context.Context, *advisorsvc.RemovePodRequest) (*advisorsvc.RemovePodResponse, error)
	ListAndWatch(*advisorsvc.Empty, CPUAdvisor_ListAndWatchServer) error
}

// UnimplementedCPUAdvisorServer can be embedded to have forward compatible implementations.
type UnimplementedCPUAdvisorServer struct {
}

func (*UnimplementedCPUAdvisorServer) AddContainer(ctx context.Context, req *advisorsvc.ContainerMetadata) (*advisorsvc.AddContainerResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method AddContainer not implemented")
}
func (*UnimplementedCPUAdvisorServer) RemovePod(ctx context.Context, req *advisorsvc.RemovePodRequest) (*advisorsvc.RemovePodResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method RemovePod not implemented")
}
func (*UnimplementedCPUAdvisorServer) ListAndWatch(req *advisorsvc.Empty, srv CPUAdvisor_ListAndWatchServer) error {
	return status.Errorf(codes.Unimplemented, "method ListAndWatch not implemented")
}

func RegisterCPUAdvisorServer(s *grpc.Server, srv CPUAdvisorServer) {
	s.RegisterService(&_CPUAdvisor_serviceDesc, srv)
}

func _CPUAdvisor_AddContainer_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(advisorsvc.ContainerMetadata)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(CPUAdvisorServer).AddContainer(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/cpuadvisor.CPUAdvisor/AddContainer",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(CPUAdvisorServer).AddContainer(ctx, req.(*advisorsvc.ContainerMetadata))
	}
	return interceptor(ctx, in, info, handler)
}

func _CPUAdvisor_RemovePod_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(advisorsvc.RemovePodRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(CPUAdvisorServer).RemovePod(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/cpuadvisor.CPUAdvisor/RemovePod",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(CPUAdvisorServer).RemovePod(ctx, req.(*advisorsvc.RemovePodRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _CPUAdvisor_ListAndWatch_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(advisorsvc.Empty)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(CPUAdvisorServer).ListAndWatch(m, &cPUAdvisorListAndWatchServer{stream})
}

type CPUAdvisor_ListAndWatchServer interface {
	Send(*ListAndWatchResponse) error
	grpc.ServerStream
}

type cPUAdvisorListAndWatchServer struct {
	grpc.ServerStream
}

func (x *cPUAdvisorListAndWatchServer) Send(m *ListAndWatchResponse) error {
	return x.ServerStream.SendMsg(m)
}

var _CPUAdvisor_serviceDesc = grpc.ServiceDesc{
	ServiceName: "cpuadvisor.CPUAdvisor",
	HandlerType: (*CPUAdvisorServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "AddContainer",
			Handler:    _CPUAdvisor_AddContainer_Handler,
		},
		{
			MethodName: "RemovePod",
			Handler:    _CPUAdvisor_RemovePod_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "ListAndWatch",
			Handler:       _CPUAdvisor_ListAndWatch_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "cpu.proto",
}

// CPUPluginClient is the client API for CPUPlugin service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type CPUPluginClient interface {
	GetCheckpoint(ctx context.Context, in *GetCheckpointRequest, opts ...grpc.CallOption) (*GetCheckpointResponse, error)
}

type cPUPluginClient struct {
	cc *grpc.ClientConn
}

func NewCPUPluginClient(cc *grpc.ClientConn) CPUPluginClient {
	return &cPUPluginClient{cc}
}

func (c *cPUPluginClient) GetCheckpoint(ctx context.Context, in *GetCheckpointRequest, opts ...grpc.CallOption) (*GetCheckpointResponse, error) {
	out := new(GetCheckpointResponse)
	err := c.cc.Invoke(ctx, "/cpuadvisor.CPUPlugin/GetCheckpoint", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// CPUPluginServer is the server API for CPUPlugin service.
type CPUPluginServer interface {
	GetCheckpoint(context.Context, *GetCheckpointRequest) (*GetCheckpointResponse, error)
}

// UnimplementedCPUPluginServer can be embedded to have forward compatible implementations.
type UnimplementedCPUPluginServer struct {
}

func (*UnimplementedCPUPluginServer) GetCheckpoint(ctx context.Context, req *GetCheckpointRequest) (*GetCheckpointResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method GetCheckpoint not implemented")
}

func RegisterCPUPluginServer(s *grpc.Server, srv CPUPluginServer) {
	s.RegisterService(&_CPUPlugin_serviceDesc, srv)
}

func _CPUPlugin_GetCheckpoint_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GetCheckpointRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(CPUPluginServer).GetCheckpoint(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/cpuadvisor.CPUPlugin/GetCheckpoint",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(CPUPluginServer).GetCheckpoint(ctx, req.(*GetCheckpointRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _CPUPlugin_serviceDesc = grpc.ServiceDesc{
	ServiceName: "cpuadvisor.CPUPlugin",
	HandlerType: (*CPUPluginServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "GetCheckpoint",
			Handler:    _CPUPlugin_GetCheckpoint_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "cpu.proto",
}

func (m *ListAndWatchResponse) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ListAndWatchResponse) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *ListAndWatchResponse) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for k := range m.Entries {
			v := m.Entries[k]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintCpu(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintCpu(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintCpu(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *CalculationEntries) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *CalculationEntries) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *CalculationEntries) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for k := range m.Entries {
			v := m.Entries[k]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintCpu(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintCpu(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintCpu(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *CalculationInfo) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *CalculationInfo) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *CalculationInfo) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.CalculationResultsByNumas) > 0 {
		for k := range m.CalculationResultsByNumas {
			v := m.CalculationResultsByNumas[k]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintCpu(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i = encodeVarintCpu(dAtA, i, uint64(k))
			i--
			dAtA[i] = 0x8
			i = encodeVarintCpu(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x12
		}
	}
	if len(m.OwnerPoolName) > 0 {
		i -= len(m.OwnerPoolName)
		copy(dAtA[i:], m.OwnerPoolName)
		i = encodeVarintCpu(dAtA, i, uint64(len(m.OwnerPoolName)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *NumaCalculationResult) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NumaCalculationResult) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *NumaCalculationResult) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Blocks) > 0 {
		for iNdEx := len(m.Blocks) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.Blocks[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintCpu(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	return len(dAtA) - i, nil
}

func (m *Block) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *Block) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *Block) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.BlockId) > 0 {
		i -= len(m.BlockId)
		copy(dAtA[i:], m.BlockId)
		i = encodeVarintCpu(dAtA, i, uint64(len(m.BlockId)))
		i--
		dAtA[i] = 0x1a
	}
	if len(m.OverlapTargets) > 0 {
		for iNdEx := len(m.OverlapTargets) - 1; iNdEx >= 0; iNdEx-- {
			{
				size, err := m.OverlapTargets[iNdEx].MarshalToSizedBuffer(dAtA[:i])
				if err != nil {
					return 0, err
				}
				i -= size
				i = encodeVarintCpu(dAtA, i, uint64(size))
			}
			i--
			dAtA[i] = 0x12
		}
	}
	if m.Result != 0 {
		i = encodeVarintCpu(dAtA, i, uint64(m.Result))
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func (m *OverlapTarget) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *OverlapTarget) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *OverlapTarget) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if m.OverlapType != 0 {
		i = encodeVarintCpu(dAtA, i, uint64(m.OverlapType))
		i--
		dAtA[i] = 0x20
	}
	if len(m.OverlapTargetContainerName) > 0 {
		i -= len(m.OverlapTargetContainerName)
		copy(dAtA[i:], m.OverlapTargetContainerName)
		i = encodeVarintCpu(dAtA, i, uint64(len(m.OverlapTargetContainerName)))
		i--
		dAtA[i] = 0x1a
	}
	if len(m.OverlapTargetPodUid) > 0 {
		i -= len(m.OverlapTargetPodUid)
		copy(dAtA[i:], m.OverlapTargetPodUid)
		i = encodeVarintCpu(dAtA, i, uint64(len(m.OverlapTargetPodUid)))
		i--
		dAtA[i] = 0x12
	}
	if len(m.OverlapTargetPoolName) > 0 {
		i -= len(m.OverlapTargetPoolName)
		copy(dAtA[i:], m.OverlapTargetPoolName)
		i = encodeVarintCpu(dAtA, i, uint64(len(m.OverlapTargetPoolName)))
		i--
		dAtA[i] = 0xa
	}
	return len(dAtA) - i, nil
}

func (m *GetCheckpointRequest) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *GetCheckpointRequest) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *GetCheckpointRequest) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	return len(dAtA) - i, nil
}

func (m *GetCheckpointResponse) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *GetCheckpointResponse) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *GetCheckpointResponse) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for k := range m.Entries {
			v := m.Entries[k]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintCpu(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintCpu(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintCpu(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *AllocationEntries) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AllocationEntries) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AllocationEntries) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for k := range m.Entries {
			v := m.Entries[k]
			baseI := i
			if v != nil {
				{
					size, err := v.MarshalToSizedBuffer(dAtA[:i])
					if err != nil {
						return 0, err
					}
					i -= size
					i = encodeVarintCpu(dAtA, i, uint64(size))
				}
				i--
				dAtA[i] = 0x12
			}
			i -= len(k)
			copy(dAtA[i:], k)
			i = encodeVarintCpu(dAtA, i, uint64(len(k)))
			i--
			dAtA[i] = 0xa
			i = encodeVarintCpu(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0xa
		}
	}
	return len(dAtA) - i, nil
}

func (m *AllocationInfo) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalToSizedBuffer(dAtA[:size])
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AllocationInfo) MarshalTo(dAtA []byte) (int, error) {
	size := m.Size()
	return m.MarshalToSizedBuffer(dAtA[:size])
}

func (m *AllocationInfo) MarshalToSizedBuffer(dAtA []byte) (int, error) {
	i := len(dAtA)
	_ = i
	var l int
	_ = l
	if len(m.OriginalTopologyAwareAssignments) > 0 {
		for k := range m.OriginalTopologyAwareAssignments {
			v := m.OriginalTopologyAwareAssignments[k]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarintCpu(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i = encodeVarintCpu(dAtA, i, uint64(k))
			i--
			dAtA[i] = 0x8
			i = encodeVarintCpu(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x22
		}
	}
	if len(m.TopologyAwareAssignments) > 0 {
		for k := range m.TopologyAwareAssignments {
			v := m.TopologyAwareAssignments[k]
			baseI := i
			i -= len(v)
			copy(dAtA[i:], v)
			i = encodeVarintCpu(dAtA, i, uint64(len(v)))
			i--
			dAtA[i] = 0x12
			i = encodeVarintCpu(dAtA, i, uint64(k))
			i--
			dAtA[i] = 0x8
			i = encodeVarintCpu(dAtA, i, uint64(baseI-i))
			i--
			dAtA[i] = 0x1a
		}
	}
	if len(m.OwnerPoolName) > 0 {
		i -= len(m.OwnerPoolName)
		copy(dAtA[i:], m.OwnerPoolName)
		i = encodeVarintCpu(dAtA, i, uint64(len(m.OwnerPoolName)))
		i--
		dAtA[i] = 0x12
	}
	if m.RampUp {
		i--
		if m.RampUp {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i--
		dAtA[i] = 0x8
	}
	return len(dAtA) - i, nil
}

func encodeVarintCpu(dAtA []byte, offset int, v uint64) int {
	offset -= sovCpu(v)
	base := offset
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return base
}
func (m *ListAndWatchResponse) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for k, v := range m.Entries {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovCpu(uint64(l))
			}
			mapEntrySize := 1 + len(k) + sovCpu(uint64(len(k))) + l
			n += mapEntrySize + 1 + sovCpu(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *CalculationEntries) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for k, v := range m.Entries {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovCpu(uint64(l))
			}
			mapEntrySize := 1 + len(k) + sovCpu(uint64(len(k))) + l
			n += mapEntrySize + 1 + sovCpu(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *CalculationInfo) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.OwnerPoolName)
	if l > 0 {
		n += 1 + l + sovCpu(uint64(l))
	}
	if len(m.CalculationResultsByNumas) > 0 {
		for k, v := range m.CalculationResultsByNumas {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovCpu(uint64(l))
			}
			mapEntrySize := 1 + sovCpu(uint64(k)) + l
			n += mapEntrySize + 1 + sovCpu(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *NumaCalculationResult) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Blocks) > 0 {
		for _, e := range m.Blocks {
			l = e.Size()
			n += 1 + l + sovCpu(uint64(l))
		}
	}
	return n
}

func (m *Block) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.Result != 0 {
		n += 1 + sovCpu(uint64(m.Result))
	}
	if len(m.OverlapTargets) > 0 {
		for _, e := range m.OverlapTargets {
			l = e.Size()
			n += 1 + l + sovCpu(uint64(l))
		}
	}
	l = len(m.BlockId)
	if l > 0 {
		n += 1 + l + sovCpu(uint64(l))
	}
	return n
}

func (m *OverlapTarget) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	l = len(m.OverlapTargetPoolName)
	if l > 0 {
		n += 1 + l + sovCpu(uint64(l))
	}
	l = len(m.OverlapTargetPodUid)
	if l > 0 {
		n += 1 + l + sovCpu(uint64(l))
	}
	l = len(m.OverlapTargetContainerName)
	if l > 0 {
		n += 1 + l + sovCpu(uint64(l))
	}
	if m.OverlapType != 0 {
		n += 1 + sovCpu(uint64(m.OverlapType))
	}
	return n
}

func (m *GetCheckpointRequest) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	return n
}

func (m *GetCheckpointResponse) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for k, v := range m.Entries {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovCpu(uint64(l))
			}
			mapEntrySize := 1 + len(k) + sovCpu(uint64(len(k))) + l
			n += mapEntrySize + 1 + sovCpu(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *AllocationEntries) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if len(m.Entries) > 0 {
		for k, v := range m.Entries {
			_ = k
			_ = v
			l = 0
			if v != nil {
				l = v.Size()
				l += 1 + sovCpu(uint64(l))
			}
			mapEntrySize := 1 + len(k) + sovCpu(uint64(len(k))) + l
			n += mapEntrySize + 1 + sovCpu(uint64(mapEntrySize))
		}
	}
	return n
}

func (m *AllocationInfo) Size() (n int) {
	if m == nil {
		return 0
	}
	var l int
	_ = l
	if m.RampUp {
		n += 2
	}
	l = len(m.OwnerPoolName)
	if l > 0 {
		n += 1 + l + sovCpu(uint64(l))
	}
	if len(m.TopologyAwareAssignments) > 0 {
		for k, v := range m.TopologyAwareAssignments {
			_ = k
			_ = v
			mapEntrySize := 1 + sovCpu(uint64(k)) + 1 + len(v) + sovCpu(uint64(len(v)))
			n += mapEntrySize + 1 + sovCpu(uint64(mapEntrySize))
		}
	}
	if len(m.OriginalTopologyAwareAssignments) > 0 {
		for k, v := range m.OriginalTopologyAwareAssignments {
			_ = k
			_ = v
			mapEntrySize := 1 + sovCpu(uint64(k)) + 1 + len(v) + sovCpu(uint64(len(v)))
			n += mapEntrySize + 1 + sovCpu(uint64(mapEntrySize))
		}
	}
	return n
}

func sovCpu(x uint64) (n int) {
	return (math_bits.Len64(x|1) + 6) / 7
}
func sozCpu(x uint64) (n int) {
	return sovCpu(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (this *ListAndWatchResponse) String() string {
	if this == nil {
		return "nil"
	}
	keysForEntries := make([]string, 0, len(this.Entries))
	for k, _ := range this.Entries {
		keysForEntries = append(keysForEntries, k)
	}
	github_com_gogo_protobuf_sortkeys.Strings(keysForEntries)
	mapStringForEntries := "map[string]*CalculationEntries{"
	for _, k := range keysForEntries {
		mapStringForEntries += fmt.Sprintf("%v: %v,", k, this.Entries[k])
	}
	mapStringForEntries += "}"
	s := strings.Join([]string{`&ListAndWatchResponse{`,
		`Entries:` + mapStringForEntries + `,`,
		`}`,
	}, "")
	return s
}
func (this *CalculationEntries) String() string {
	if this == nil {
		return "nil"
	}
	keysForEntries := make([]string, 0, len(this.Entries))
	for k, _ := range this.Entries {
		keysForEntries = append(keysForEntries, k)
	}
	github_com_gogo_protobuf_sortkeys.Strings(keysForEntries)
	mapStringForEntries := "map[string]*CalculationInfo{"
	for _, k := range keysForEntries {
		mapStringForEntries += fmt.Sprintf("%v: %v,", k, this.Entries[k])
	}
	mapStringForEntries += "}"
	s := strings.Join([]string{`&CalculationEntries{`,
		`Entries:` + mapStringForEntries + `,`,
		`}`,
	}, "")
	return s
}
func (this *CalculationInfo) String() string {
	if this == nil {
		return "nil"
	}
	keysForCalculationResultsByNumas := make([]int64, 0, len(this.CalculationResultsByNumas))
	for k, _ := range this.CalculationResultsByNumas {
		keysForCalculationResultsByNumas = append(keysForCalculationResultsByNumas, k)
	}
	github_com_gogo_protobuf_sortkeys.Int64s(keysForCalculationResultsByNumas)
	mapStringForCalculationResultsByNumas := "map[int64]*NumaCalculationResult{"
	for _, k := range keysForCalculationResultsByNumas {
		mapStringForCalculationResultsByNumas += fmt.Sprintf("%v: %v,", k, this.CalculationResultsByNumas[k])
	}
	mapStringForCalculationResultsByNumas += "}"
	s := strings.Join([]string{`&CalculationInfo{`,
		`OwnerPoolName:` + fmt.Sprintf("%v", this.OwnerPoolName) + `,`,
		`CalculationResultsByNumas:` + mapStringForCalculationResultsByNumas + `,`,
		`}`,
	}, "")
	return s
}
func (this *NumaCalculationResult) String() string {
	if this == nil {
		return "nil"
	}
	repeatedStringForBlocks := "[]*Block{"
	for _, f := range this.Blocks {
		repeatedStringForBlocks += strings.Replace(f.String(), "Block", "Block", 1) + ","
	}
	repeatedStringForBlocks += "}"
	s := strings.Join([]string{`&NumaCalculationResult{`,
		`Blocks:` + repeatedStringForBlocks + `,`,
		`}`,
	}, "")
	return s
}
func (this *Block) String() string {
	if this == nil {
		return "nil"
	}
	repeatedStringForOverlapTargets := "[]*OverlapTarget{"
	for _, f := range this.OverlapTargets {
		repeatedStringForOverlapTargets += strings.Replace(f.String(), "OverlapTarget", "OverlapTarget", 1) + ","
	}
	repeatedStringForOverlapTargets += "}"
	s := strings.Join([]string{`&Block{`,
		`Result:` + fmt.Sprintf("%v", this.Result) + `,`,
		`OverlapTargets:` + repeatedStringForOverlapTargets + `,`,
		`BlockId:` + fmt.Sprintf("%v", this.BlockId) + `,`,
		`}`,
	}, "")
	return s
}
func (this *OverlapTarget) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&OverlapTarget{`,
		`OverlapTargetPoolName:` + fmt.Sprintf("%v", this.OverlapTargetPoolName) + `,`,
		`OverlapTargetPodUid:` + fmt.Sprintf("%v", this.OverlapTargetPodUid) + `,`,
		`OverlapTargetContainerName:` + fmt.Sprintf("%v", this.OverlapTargetContainerName) + `,`,
		`OverlapType:` + fmt.Sprintf("%v", this.OverlapType) + `,`,
		`}`,
	}, "")
	return s
}
func (this *GetCheckpointRequest) String() string {
	if this == nil {
		return "nil"
	}
	s := strings.Join([]string{`&GetCheckpointRequest{`,
		`}`,
	}, "")
	return s
}
func (this *GetCheckpointResponse) String() string {
	if this == nil {
		return "nil"
	}
	keysForEntries := make([]string, 0, len(this.Entries))
	for k, _ := range this.Entries {
		keysForEntries = append(keysForEntries, k)
	}
	github_com_gogo_protobuf_sortkeys.Strings(keysForEntries)
	mapStringForEntries := "map[string]*AllocationEntries{"
	for _, k := range keysForEntries {
		mapStringForEntries += fmt.Sprintf("%v: %v,", k, this.Entries[k])
	}
	mapStringForEntries += "}"
	s := strings.Join([]string{`&GetCheckpointResponse{`,
		`Entries:` + mapStringForEntries + `,`,
		`}`,
	}, "")
	return s
}
func (this *AllocationEntries) String() string {
	if this == nil {
		return "nil"
	}
	keysForEntries := make([]string, 0, len(this.Entries))
	for k, _ := range this.Entries {
		keysForEntries = append(keysForEntries, k)
	}
	github_com_gogo_protobuf_sortkeys.Strings(keysForEntries)
	mapStringForEntries := "map[string]*AllocationInfo{"
	for _, k := range keysForEntries {
		mapStringForEntries += fmt.Sprintf("%v: %v,", k, this.Entries[k])
	}
	mapStringForEntries += "}"
	s := strings.Join([]string{`&AllocationEntries{`,
		`Entries:` + mapStringForEntries + `,`,
		`}`,
	}, "")
	return s
}
func (this *AllocationInfo) String() string {
	if this == nil {
		return "nil"
	}
	keysForTopologyAwareAssignments := make([]uint64, 0, len(this.TopologyAwareAssignments))
	for k, _ := range this.TopologyAwareAssignments {
		keysForTopologyAwareAssignments = append(keysForTopologyAwareAssignments, k)
	}
	github_com_gogo_protobuf_sortkeys.Uint64s(keysForTopologyAwareAssignments)
	mapStringForTopologyAwareAssignments := "map[uint64]string{"
	for _, k := range keysForTopologyAwareAssignments {
		mapStringForTopologyAwareAssignments += fmt.Sprintf("%v: %v,", k, this.TopologyAwareAssignments[k])
	}
	mapStringForTopologyAwareAssignments += "}"
	keysForOriginalTopologyAwareAssignments := make([]uint64, 0, len(this.OriginalTopologyAwareAssignments))
	for k, _ := range this.OriginalTopologyAwareAssignments {
		keysForOriginalTopologyAwareAssignments = append(keysForOriginalTopologyAwareAssignments, k)
	}
	github_com_gogo_protobuf_sortkeys.Uint64s(keysForOriginalTopologyAwareAssignments)
	mapStringForOriginalTopologyAwareAssignments := "map[uint64]string{"
	for _, k := range keysForOriginalTopologyAwareAssignments {
		mapStringForOriginalTopologyAwareAssignments += fmt.Sprintf("%v: %v,", k, this.OriginalTopologyAwareAssignments[k])
	}
	mapStringForOriginalTopologyAwareAssignments += "}"
	s := strings.Join([]string{`&AllocationInfo{`,
		`RampUp:` + fmt.Sprintf("%v", this.RampUp) + `,`,
		`OwnerPoolName:` + fmt.Sprintf("%v", this.OwnerPoolName) + `,`,
		`TopologyAwareAssignments:` + mapStringForTopologyAwareAssignments + `,`,
		`OriginalTopologyAwareAssignments:` + mapStringForOriginalTopologyAwareAssignments + `,`,
		`}`,
	}, "")
	return s
}
func valueToStringCpu(v interface{}) string {
	rv := reflect.ValueOf(v)
	if rv.IsNil() {
		return "nil"
	}
	pv := reflect.Indirect(rv).Interface()
	return fmt.Sprintf("*%v", pv)
}
func (m *ListAndWatchResponse) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ListAndWatchResponse: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ListAndWatchResponse: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Entries", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Entries == nil {
				m.Entries = make(map[string]*CalculationEntries)
			}
			var mapkey string
			var mapvalue *CalculationEntries
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowCpu
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthCpu
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthCpu
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthCpu
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthCpu
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &CalculationEntries{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipCpu(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthCpu
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.Entries[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *CalculationEntries) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: CalculationEntries: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: CalculationEntries: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Entries", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Entries == nil {
				m.Entries = make(map[string]*CalculationInfo)
			}
			var mapkey string
			var mapvalue *CalculationInfo
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowCpu
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthCpu
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthCpu
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthCpu
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthCpu
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &CalculationInfo{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipCpu(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthCpu
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.Entries[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *CalculationInfo) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: CalculationInfo: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: CalculationInfo: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OwnerPoolName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OwnerPoolName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CalculationResultsByNumas", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.CalculationResultsByNumas == nil {
				m.CalculationResultsByNumas = make(map[int64]*NumaCalculationResult)
			}
			var mapkey int64
			var mapvalue *NumaCalculationResult
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowCpu
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= int64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthCpu
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthCpu
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &NumaCalculationResult{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipCpu(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthCpu
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.CalculationResultsByNumas[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NumaCalculationResult) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NumaCalculationResult: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NumaCalculationResult: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Blocks", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Blocks = append(m.Blocks, &Block{})
			if err := m.Blocks[len(m.Blocks)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *Block) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: Block: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: Block: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Result", wireType)
			}
			m.Result = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Result |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OverlapTargets", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OverlapTargets = append(m.OverlapTargets, &OverlapTarget{})
			if err := m.OverlapTargets[len(m.OverlapTargets)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BlockId", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.BlockId = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *OverlapTarget) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: OverlapTarget: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: OverlapTarget: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OverlapTargetPoolName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OverlapTargetPoolName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OverlapTargetPodUid", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OverlapTargetPodUid = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OverlapTargetContainerName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OverlapTargetContainerName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 4:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OverlapType", wireType)
			}
			m.OverlapType = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OverlapType |= OverlapType(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *GetCheckpointRequest) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: GetCheckpointRequest: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: GetCheckpointRequest: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *GetCheckpointResponse) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: GetCheckpointResponse: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: GetCheckpointResponse: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Entries", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Entries == nil {
				m.Entries = make(map[string]*AllocationEntries)
			}
			var mapkey string
			var mapvalue *AllocationEntries
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowCpu
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthCpu
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthCpu
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthCpu
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthCpu
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &AllocationEntries{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipCpu(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthCpu
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.Entries[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AllocationEntries) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AllocationEntries: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AllocationEntries: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Entries", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Entries == nil {
				m.Entries = make(map[string]*AllocationInfo)
			}
			var mapkey string
			var mapvalue *AllocationInfo
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowCpu
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					var stringLenmapkey uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapkey := int(stringLenmapkey)
					if intStringLenmapkey < 0 {
						return ErrInvalidLengthCpu
					}
					postStringIndexmapkey := iNdEx + intStringLenmapkey
					if postStringIndexmapkey < 0 {
						return ErrInvalidLengthCpu
					}
					if postStringIndexmapkey > l {
						return io.ErrUnexpectedEOF
					}
					mapkey = string(dAtA[iNdEx:postStringIndexmapkey])
					iNdEx = postStringIndexmapkey
				} else if fieldNum == 2 {
					var mapmsglen int
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapmsglen |= int(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					if mapmsglen < 0 {
						return ErrInvalidLengthCpu
					}
					postmsgIndex := iNdEx + mapmsglen
					if postmsgIndex < 0 {
						return ErrInvalidLengthCpu
					}
					if postmsgIndex > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = &AllocationInfo{}
					if err := mapvalue.Unmarshal(dAtA[iNdEx:postmsgIndex]); err != nil {
						return err
					}
					iNdEx = postmsgIndex
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipCpu(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthCpu
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.Entries[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AllocationInfo) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= uint64(b&0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AllocationInfo: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AllocationInfo: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field RampUp", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.RampUp = bool(v != 0)
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OwnerPoolName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= uint64(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + intStringLen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.OwnerPoolName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field TopologyAwareAssignments", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.TopologyAwareAssignments == nil {
				m.TopologyAwareAssignments = make(map[uint64]string)
			}
			var mapkey uint64
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowCpu
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthCpu
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue < 0 {
						return ErrInvalidLengthCpu
					}
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipCpu(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthCpu
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.TopologyAwareAssignments[mapkey] = mapvalue
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OriginalTopologyAwareAssignments", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= int(b&0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthCpu
			}
			postIndex := iNdEx + msglen
			if postIndex < 0 {
				return ErrInvalidLengthCpu
			}
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OriginalTopologyAwareAssignments == nil {
				m.OriginalTopologyAwareAssignments = make(map[uint64]string)
			}
			var mapkey uint64
			var mapvalue string
			for iNdEx < postIndex {
				entryPreIndex := iNdEx
				var wire uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowCpu
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					wire |= uint64(b&0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				fieldNum := int32(wire >> 3)
				if fieldNum == 1 {
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						mapkey |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
				} else if fieldNum == 2 {
					var stringLenmapvalue uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowCpu
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						stringLenmapvalue |= uint64(b&0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					intStringLenmapvalue := int(stringLenmapvalue)
					if intStringLenmapvalue < 0 {
						return ErrInvalidLengthCpu
					}
					postStringIndexmapvalue := iNdEx + intStringLenmapvalue
					if postStringIndexmapvalue < 0 {
						return ErrInvalidLengthCpu
					}
					if postStringIndexmapvalue > l {
						return io.ErrUnexpectedEOF
					}
					mapvalue = string(dAtA[iNdEx:postStringIndexmapvalue])
					iNdEx = postStringIndexmapvalue
				} else {
					iNdEx = entryPreIndex
					skippy, err := skipCpu(dAtA[iNdEx:])
					if err != nil {
						return err
					}
					if (skippy < 0) || (iNdEx+skippy) < 0 {
						return ErrInvalidLengthCpu
					}
					if (iNdEx + skippy) > postIndex {
						return io.ErrUnexpectedEOF
					}
					iNdEx += skippy
				}
			}
			m.OriginalTopologyAwareAssignments[mapkey] = mapvalue
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipCpu(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if (skippy < 0) || (iNdEx+skippy) < 0 {
				return ErrInvalidLengthCpu
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipCpu(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	depth := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowCpu
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
		case 1:
			iNdEx += 8
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowCpu
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if length < 0 {
				return 0, ErrInvalidLengthCpu
			}
			iNdEx += length
		case 3:
			depth++
		case 4:
			if depth == 0 {
				return 0, ErrUnexpectedEndOfGroupCpu
			}
			depth--
		case 5:
			iNdEx += 4
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
		if iNdEx < 0 {
			return 0, ErrInvalidLengthCpu
		}
		if depth == 0 {
			return iNdEx, nil
		}
	}
	return 0, io.ErrUnexpectedEOF
}

var (
	ErrInvalidLengthCpu        = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowCpu          = fmt.Errorf("proto: integer overflow")
	ErrUnexpectedEndOfGroupCpu = fmt.Errorf("proto: unexpected end of group")
)
